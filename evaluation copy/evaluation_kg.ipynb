{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from db.datasets import datasets\n",
    "from config import system_configs\n",
    "import json, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open('config/KPGrouping.json', \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "    \n",
    "split = 'valchart'\n",
    "\n",
    "configs[\"system\"][\"data_dir\"] = \"/root/autodl-tmp/extraction_data\"\n",
    "configs[\"system\"][\"cache_dir\"] = \"data/cache/\"\n",
    "\n",
    "configs[\"system\"][\"dataset\"] =  \"Chart\"\n",
    "configs[\"system\"][\"snapshot_name\"] = \"PretrainKP\"\n",
    "system_configs.update_config(configs[\"system\"])\n",
    "db = datasets[\"Chart\"](configs[\"db\"], split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_pie_center(a, b, c):\n",
    "    a,b,c = np.array(a), np.array(b), np.array(c)\n",
    "    ca = c - a\n",
    "    cb = c - b\n",
    "    # 计算向量 ca 和 cb 之间的角度的余弦值。\n",
    "    cosine_angle = np.dot(ca, cb) / (np.linalg.norm(ca) * np.linalg.norm(cb))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    r_square = (ca**2).sum()\n",
    "   # 判断向量 ca 和 cb 的叉积的符号。这一步用于确定扇形是在向量 ca 和 cb 之间还是在向量 ca 和 cb 之外。 \n",
    "    if ca[0]*cb[1]-ca[1]*cb[0] >= 0:\n",
    "        # 如果叉积大于或等于 0，则返回扇形的几何中心和面积（这里假设扇形是在向量 ca 和 cb 之间）。\n",
    "        return (a[0]+b[0]+c[0])/3., (a[1]+b[1]+c[1])/3., 0.5 * angle * r_square\n",
    "    else:\n",
    "        # 否则，返回扇形外侧的几何中心和面积。\n",
    "        return 2*c[0]-(a[0]+b[0]+c[0])/3., 2*c[1]-(a[1]+b[1]+c[1])/3., np.pi * r_square - 0.5 * angle * r_square\n",
    "\n",
    "def get_grouped_points(gts, preds, chartType):\n",
    "    gt_groups = []\n",
    "    area = 0\n",
    "        \n",
    "    if chartType == 'vbar_categorical':\n",
    "        # 遍历所有 ground truth 边界框。\n",
    "        for bbox in gts:\n",
    "            # 计算边界框的面积。\n",
    "            area = np.abs((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])) \n",
    "            # 如果面积为 0，则跳过这个边界框。\n",
    "            if area == 0: continue\n",
    "            # 将非零面积的 ground truth 添加到 gt_groups。\n",
    "            gt_groups.append((bbox[:-1].reshape(-1, 2), area))\n",
    "    elif chartType == 'pie':\n",
    "        for bbox in gts:\n",
    "            # 处理逻辑与条形图类似，但是使用了 get_pie_center 函数来计算饼图分片的面积。\n",
    "            a, b, c = (bbox[0], bbox[1]), (bbox[2], bbox[3]), (bbox[4], bbox[5])\n",
    "            _, _, area = get_pie_center(a,b,c)        \n",
    "            if area == 0: continue\n",
    "            gt_groups.append((bbox[:-1].reshape(-1, 2), area))\n",
    "    elif chartType == 'line':\n",
    "        for bbox in gts:\n",
    "            # 遍历 ground truth，并使用特定的计算方式来获取面积。\n",
    "            detection = np.array(bbox)\n",
    "            if len(detection) <= 1: continue\n",
    "            assert len(detection) % 2 == 0\n",
    "            \n",
    "            xs = detection[0:len(detection):2]\n",
    "            ys = detection[1:len(detection):2]\n",
    "            area = (max(max(xs) - min(xs), max(ys) - min(ys)) / len(detection) * 2) ** 2\n",
    "            if area == 0: continue\n",
    "                \n",
    "            gt_groups.append((bbox.reshape(-1, 2), area))   \n",
    "\n",
    "    pred_groups = []\n",
    "    if '1' not in preds[0]: # baseline predictions\n",
    "        if chartType == 'pie':\n",
    "            for pred in preds:\n",
    "                pred_groups.append(np.array(pred[:-1]))\n",
    "        elif chartType == 'line':\n",
    "            for pred in preds:\n",
    "                pred_groups.append(np.array(pred))\n",
    "        else:\n",
    "            for pred in preds:\n",
    "                pred_groups.append(np.array(pred).reshape(-1, 2))\n",
    "    else:\n",
    "        for pred in preds[2]:\n",
    "            pred_groups.append(np.array(pred[2:-1]).reshape(-1, 2))\n",
    "    return gt_groups, pred_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 计算 Object Keypoint Similarity（物体关键点相似度）。这是一种常用于评估物体检测和关键点估计任务性能的指标。\n",
    "def OKS(gt_p, pred_p, area):\n",
    "    # 计算了两个二维点（gt_p 为 ground truth 点，pred_p 为预测点）之间的欧氏距离的平方。\n",
    "    d2 = (gt_p[0] - pred_p[0]) ** 2 + (gt_p[1] - pred_p[1]) ** 2\n",
    "    # 一个常数，用于调整距离的权重。这个值可以根据具体应用进行调整。\n",
    "    k2 = 0.1\n",
    "    # 将函数输入的 area 直接赋值给 s2，表示物体或特征的面积。面积越大，对距离的容忍度越高。\n",
    "    s2 = area\n",
    "    #  OKS 的计算公式。函数返回一个介于 0 和 1 之间的值，用于表示 gt_p 和 pred_p 之间的相似度。值越接近 1，表示两点越相似。\n",
    "    return np.exp(d2/(s2 * k2) * (-1))\n",
    "\n",
    "# 计算一组物体关键点（gt_ps 为 ground truth 关键点，pred_ps 为预测关键点）之间的平均 Object Keypoint Similarity（OKS）。\n",
    "def GroupOKS(gt_ps, pred_ps):\n",
    "    # 初始化一个空列表，用于存储每个预测点与所有 ground truth 点之间的最大 OKS。\n",
    "    group_score = []\n",
    "    for pred_p in pred_ps:\n",
    "        # 初始化 max_score 为 0，用于存储当前预测点与所有 ground truth 点之间的最大 OKS。\n",
    "        max_score = 0.\n",
    "        for gt_p in gt_ps[0]:\n",
    "            max_score = max(max_score, OKS(gt_p, pred_p, gt_ps[1]))\n",
    "        group_score.append(max_score)\n",
    "        # 计算 group_score 列表中所有 OKS 的平均值，并返回。\n",
    "    return sum(group_score)/len(group_score)\n",
    "\n",
    "def computePrecision(gt_groups, pred_groups, thres=0.75):\n",
    "    count = 0\n",
    "    for pred_ps in pred_groups:\n",
    "        for gt_ps in gt_groups:\n",
    "            if GroupOKS(gt_ps, pred_ps) > thres:\n",
    "                count += 1\n",
    "                break\n",
    "\n",
    "    return count / len(pred_groups)\n",
    "\n",
    "def computeRecall(gt_groups, pred_groups, thres=0.75):\n",
    "    count = 0\n",
    "    for gt_ps in gt_groups:\n",
    "        for pred_ps in pred_groups:\n",
    "            if GroupOKS(gt_ps, pred_ps) > thres:\n",
    "                count += 1\n",
    "                break\n",
    "\n",
    "    return count / len(gt_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open('evaluation/KPGrouping5000.json') as f:\n",
    "    prediction = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# compute 0.75\n",
    "macro_P = []\n",
    "macro_R = []\n",
    "max_iter = db.db_inds.size\n",
    "\n",
    "for i in tqdm(range(max_iter)):\n",
    "    chartType = None\n",
    "    db_ind = db.db_inds[i]\n",
    "    image_file = db.image_file(db_ind)\n",
    "    gts = db.detections(db_ind)\n",
    "    preds = prediction[image_file.split('/')[-1]]\n",
    "    if preds is None or len(preds) == 0: continue\n",
    "    if len(preds) == 3 and len(preds[2]) == 0: continue\n",
    "    \n",
    "    print(preds)\n",
    "    if gts is None or len(gts) == 0: continue\n",
    "    print(gts)\n",
    "    gts = gts[0] if chartType == 'line' else gts\n",
    "    if len(gts) == 0: continue\n",
    "    gt_groups, pred_groups = get_grouped_points(gts, preds, chartType)\n",
    "\n",
    "    P = computePrecision(gt_groups, pred_groups, thres=0.75)\n",
    "    R = computeRecall(gt_groups, pred_groups, thres=0.75)\n",
    "    \n",
    "    macro_P.append(P)\n",
    "    macro_R.append(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "macro_P = np.array(macro_P)\n",
    "macro_R = np.array(macro_R)\n",
    "macro_P_avg = macro_P[~np.isnan(macro_P)].mean()\n",
    "macro_R_avg = macro_R[~np.isnan(macro_R)].mean()\n",
    "print('macro_P:', macro_P_avg, \" macro_R:\", macro_R_avg, 'F score:', (2*macro_P_avg*macro_R_avg) / (macro_P_avg + macro_R_avg))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
